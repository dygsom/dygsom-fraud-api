# ============================================================================
# DYGSOM Fraud API - Nginx Load Balancer Configuration
# ============================================================================
# This configuration provides:
# - Load balancing across 3 API instances (least_conn algorithm)
# - Health checks with automatic failover
# - Rate limiting to prevent abuse
# - Request/response compression
# - Security headers
# - Access logging and monitoring
#
# Performance Targets:
#   - Throughput: 300+ req/sec across all instances
#   - P95 Latency: <100ms
#   - High Availability: 99.9% uptime
# ============================================================================

user nginx;
worker_processes auto;  # Auto-detect CPU cores
worker_rlimit_nofile 65535;  # Increase file descriptor limit

error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 4096;  # Max concurrent connections per worker
    use epoll;  # Efficient event model for Linux
    multi_accept on;  # Accept multiple connections at once
}

http {
    # ========================================================================
    # BASIC SETTINGS
    # ========================================================================
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging format with detailed metrics
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    log_format detailed '$remote_addr - $remote_user [$time_local] '
                        '"$request" $status $body_bytes_sent '
                        '"$http_referer" "$http_user_agent" '
                        'rt=$request_time uct="$upstream_connect_time" '
                        'uht="$upstream_header_time" urt="$upstream_response_time" '
                        'upstream=$upstream_addr upstream_status=$upstream_status';

    access_log /var/log/nginx/access.log detailed;

    # ========================================================================
    # PERFORMANCE TUNING
    # ========================================================================
    sendfile on;  # Efficient file transmission
    tcp_nopush on;  # Send headers in one packet
    tcp_nodelay on;  # Don't buffer data

    keepalive_timeout 65;  # Client keepalive timeout
    keepalive_requests 1000;  # Max requests per keepalive connection

    types_hash_max_size 2048;
    server_tokens off;  # Hide nginx version

    # Buffer sizes
    client_body_buffer_size 128k;
    client_max_body_size 10m;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 16k;

    # Timeouts
    client_body_timeout 12;
    client_header_timeout 12;
    send_timeout 10;

    # File descriptor cache
    open_file_cache max=1000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;

    # ========================================================================
    # GZIP COMPRESSION
    # ========================================================================
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;  # Balanced compression (1-9)
    gzip_min_length 1024;  # Only compress responses > 1KB
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/rss+xml
        application/atom+xml
        image/svg+xml;

    # ========================================================================
    # RATE LIMITING
    # ========================================================================
    # Zone for rate limiting by IP (10MB = ~160k IPs)
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/m;
    limit_req_zone $binary_remote_addr zone=api_burst:10m rate=200r/m;

    # Connection limiting
    limit_conn_zone $binary_remote_addr zone=addr:10m;

    # Request body size limiting
    limit_req_status 429;
    limit_conn_status 429;

    # ========================================================================
    # UPSTREAM - API INSTANCES
    # ========================================================================
    # Load balancing configuration with health checks
    # Algorithm: least_conn (send requests to instance with fewest active connections)
    # ========================================================================
    upstream fraud_api_backend {
        # Load balancing algorithm
        least_conn;  # Route to instance with least active connections

        # API instances
        server api-1:3000 max_fails=3 fail_timeout=30s;
        server api-2:3000 max_fails=3 fail_timeout=30s;
        server api-3:3000 max_fails=3 fail_timeout=30s;

        # Connection keepalive to backend
        keepalive 32;  # Keep 32 idle connections to each backend
        keepalive_requests 100;  # Max requests per keepalive connection
        keepalive_timeout 60s;  # Idle timeout for keepalive connections
    }

    # ========================================================================
    # MAIN SERVER BLOCK
    # ========================================================================
    server {
        listen 80;
        server_name localhost fraud-api.local;

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "no-referrer-when-downgrade" always;

        # ====================================================================
        # HEALTH CHECK ENDPOINT (bypasses load balancer)
        # ====================================================================
        location /health {
            access_log off;  # Don't log health checks

            # Direct health check to first instance
            proxy_pass http://api-1:3000/health;
            proxy_http_version 1.1;
            proxy_set_header Connection "";

            # Quick timeout for health checks
            proxy_connect_timeout 2s;
            proxy_send_timeout 2s;
            proxy_read_timeout 2s;
        }

        # ====================================================================
        # METRICS ENDPOINT (Prometheus scraping)
        # ====================================================================
        location /metrics {
            access_log off;

            # Aggregate metrics from all instances
            proxy_pass http://fraud_api_backend/metrics;
            proxy_http_version 1.1;
            proxy_set_header Connection "";

            # Restrict to internal network only (optional)
            # allow 172.20.0.0/16;
            # deny all;
        }

        # ====================================================================
        # API ENDPOINTS (load balanced)
        # ====================================================================
        location /api/ {
            # Rate limiting
            limit_req zone=api_limit burst=20 nodelay;
            limit_req zone=api_burst burst=50 nodelay;
            limit_conn addr 10;  # Max 10 concurrent connections per IP

            # Proxy to backend
            proxy_pass http://fraud_api_backend;
            proxy_http_version 1.1;

            # Headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Connection "";  # Enable keepalive

            # Timeouts
            proxy_connect_timeout 5s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;

            # Buffering
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;

            # Error handling
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503;
            proxy_next_upstream_tries 2;
            proxy_next_upstream_timeout 10s;

            # Cache control
            add_header X-Cache-Status $upstream_cache_status;
        }

        # ====================================================================
        # DOCS ENDPOINTS (Swagger/OpenAPI)
        # ====================================================================
        location /docs {
            proxy_pass http://fraud_api_backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header Connection "";
        }

        location /openapi.json {
            proxy_pass http://fraud_api_backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header Connection "";

            # Cache OpenAPI spec for 5 minutes
            proxy_cache_valid 200 5m;
        }

        # ====================================================================
        # ROOT / DEFAULT
        # ====================================================================
        location / {
            # Redirect to docs
            return 301 /docs;
        }

        # ====================================================================
        # ERROR PAGES
        # ====================================================================
        error_page 429 /429.json;
        location = /429.json {
            internal;
            default_type application/json;
            return 429 '{"error": "Too Many Requests", "message": "Rate limit exceeded. Please try again later."}';
        }

        error_page 502 503 504 /50x.json;
        location = /50x.json {
            internal;
            default_type application/json;
            return 503 '{"error": "Service Unavailable", "message": "The API is temporarily unavailable. Please try again later."}';
        }
    }

    # ========================================================================
    # HTTPS SERVER (SSL/TLS)
    # ========================================================================
    # Uncomment and configure for production use
    # ========================================================================
    # server {
    #     listen 443 ssl http2;
    #     server_name fraud-api.example.com;
    #
    #     # SSL certificates
    #     ssl_certificate /etc/nginx/ssl/fullchain.pem;
    #     ssl_certificate_key /etc/nginx/ssl/privkey.pem;
    #
    #     # SSL configuration (Mozilla Intermediate)
    #     ssl_protocols TLSv1.2 TLSv1.3;
    #     ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384';
    #     ssl_prefer_server_ciphers off;
    #
    #     # SSL session cache
    #     ssl_session_cache shared:SSL:10m;
    #     ssl_session_timeout 10m;
    #     ssl_session_tickets off;
    #
    #     # HSTS (HTTP Strict Transport Security)
    #     add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload" always;
    #
    #     # Use same location blocks as HTTP server
    #     include /etc/nginx/conf.d/api-locations.conf;
    # }

    # Redirect HTTP to HTTPS (when SSL is enabled)
    # server {
    #     listen 80;
    #     server_name fraud-api.example.com;
    #     return 301 https://$server_name$request_uri;
    # }

    # ========================================================================
    # STATUS PAGE (Nginx stub_status for monitoring)
    # ========================================================================
    server {
        listen 8080;
        server_name localhost;

        location /nginx_status {
            stub_status on;
            access_log off;

            # Restrict to internal network
            allow 172.20.0.0/16;
            deny all;
        }
    }
}

# ============================================================================
# CONFIGURATION NOTES
# ============================================================================
# 1. Load Balancing Algorithm: least_conn
#    - Routes requests to the backend with fewest active connections
#    - Better than round-robin for varying request durations
#    - Alternative: ip_hash (sticky sessions based on client IP)
#
# 2. Health Checks:
#    - Passive: max_fails=3, fail_timeout=30s
#    - Active health checks require nginx-plus or custom script
#
# 3. Rate Limiting:
#    - API endpoints: 100 req/min per IP (burst: 20)
#    - Burst handling: 200 req/min (burst: 50)
#    - Configurable per location block
#
# 4. Connection Keepalive:
#    - Client: 65s timeout, 1000 requests max
#    - Backend: 60s timeout, 100 requests max, 32 idle connections
#
# 5. Timeouts:
#    - Connect: 5s (time to establish backend connection)
#    - Send: 30s (time to send request to backend)
#    - Read: 30s (time to read response from backend)
#
# 6. Error Handling:
#    - Automatic failover on errors (proxy_next_upstream)
#    - Max 2 retry attempts
#    - 10s total timeout for retries
#
# 7. Monitoring:
#    - Detailed access logs with upstream timing
#    - Stub status at :8080/nginx_status
#    - Prometheus metrics from /metrics endpoint
#
# 8. Security:
#    - Rate limiting per IP
#    - Security headers (X-Frame-Options, X-Content-Type-Options, etc.)
#    - Server tokens hidden
#    - SSL/TLS ready (commented out)
#
# ============================================================================
# TESTING THE LOAD BALANCER
# ============================================================================
# 1. Start the scaled deployment:
#    docker-compose -f scaling/docker-compose-scaled.yml up -d
#
# 2. Test load balancing:
#    for i in {1..10}; do curl -H "X-API-Key: dygsom_test_api_key_change_me" \
#      http://localhost/api/v1/fraud/score -X POST \
#      -d '{"transaction_id":"test-'$i'","customer_email":"test@example.com",...}'; done
#
# 3. Check which backends are handling requests:
#    docker-compose -f scaling/docker-compose-scaled.yml logs -f nginx | grep upstream
#
# 4. Monitor nginx status:
#    curl http://localhost:8080/nginx_status
#
# 5. Test failover (stop one instance):
#    docker stop fraud-api-1
#    # Requests should automatically route to api-2 and api-3
#
# 6. Run load test:
#    locust -f load_testing/locustfile.py --host=http://localhost \
#           --users 300 --spawn-rate 30 --run-time 5m
#
# ============================================================================
